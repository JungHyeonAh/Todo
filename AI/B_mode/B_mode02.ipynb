{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28c7d5d-b91e-4200-831b-95e667891c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder  # label 수로 변환\n",
    "\n",
    "import splitfolders  # 데이터를 train, val, test폴더로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384f1baa-267c-48e5-bb94-c1e01c345eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로\n",
    "path = 'C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e385ebc-5641-4123-90e0-fe4370434a97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_error(self, image):\n",
    "    lines = self.detect_lines_thickness(image)\n",
    "    line_thickness_threshold = 0.3\n",
    "    line_cnt = detect_line_count(image)\n",
    "\n",
    "    if len(lines) >= line_cnt:\n",
    "        for line in lines:\n",
    "            if line[\"thickness\"] >= line_thickness_threshold:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def detect_line_thickness(image):\n",
    "    # 이미지 이진화\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 선의 굵기 측정\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    line_thickness = 0\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        line_thickness = max(line_thickness, w, h)\n",
    "\n",
    "    return line_thickness\n",
    "\n",
    "\n",
    "def detect_line_count(image):\n",
    "    # 이미지 이진화\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 선 탐지\n",
    "    edges = cv2.Canny(binary_image, 50, 150)\n",
    "\n",
    "    # 선의 개수 측정\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=50)\n",
    "    line_count = 0 if lines is None else len(lines)\n",
    "\n",
    "    return line_count\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path, 0)  # 흑백 이미지로 로드\n",
    "    \n",
    "    line_thickness = detect_line_thickness(image)\n",
    "    line_count = detect_line_count(image)\n",
    "\n",
    "    if line_thickness >= 0.4 or line_count >= 5:\n",
    "        # 오류 처리\n",
    "        # 여기에 오류로 처리하는 로직을 추가하거나, 해당 이미지를 오류 데이터로 분류하는 등의 작업을 수행합니다.\n",
    "        print(f\"Error: {image_path}\")\n",
    "    else:\n",
    "        # 정상 처리\n",
    "        # 여기에 정상적으로 처리하는 로직을 추가합니다.\n",
    "        print(f\"Processed: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "534cddd1-46cc-4aa4-9d3a-daafb29a2ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        \n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.image_list = self.load_image_list(path)\n",
    "    \n",
    "    \n",
    "    def load_image_list(self, path, is_training=True):\n",
    "        image_list = []\n",
    "        \n",
    "        # train, validation 폴더의 경우 Broken, Normal폴더로 나뉘어져 있음.\n",
    "        if is_training:            \n",
    "            for foldername in os.listdir(path):  # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test\n",
    "                if foldername == 'Broken' or foldername == 'Normal':\n",
    "                    folder = os.path.join(path, foldername)   # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test \\\\ Broken\n",
    "                    print(folder)\n",
    "                    # Normal, Broken 이미지\n",
    "                    for filename in os.listdir(folder):\n",
    "                        #print(filename)\n",
    "                        if filename.endswith(\".jpg\") or filename.endswith(\".PNG\"):\n",
    "                            \n",
    "                            image_path = os.path.join(folder, filename)\n",
    "                            image_list.append((image_path, filename))  # 레이블 폴더명으로 추가\n",
    "                            \n",
    "        # test폴더의 경우 Broken, Normal 폴더가 없고 두 개의 이미지가 혼합되어있음.        \n",
    "        else:\n",
    "            for filename in os.listdir(path):\n",
    "                if filename.endswith(\".jpg\") or filename.endswith(\".PNG\"):\n",
    "                    image_path_test = os.path.join(path, filename)\n",
    "                    image_list.append(image_path_test)\n",
    "        return image_list\n",
    "\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    \n",
    "    def getitem(self, index):\n",
    "        if self.is_training:\n",
    "            image_path, label = self.image_list[index]\n",
    "            image = Image.open(image_path) # .convert(\"L\")  # 흑백 이미지로 변환\n",
    "            \n",
    "            #lines = self.detect_lines(image)\n",
    "            # 선 굵기와 개수를 기반으로 오류 여부 판단\n",
    "            #is_error = lines[\"thickness\"] >= 0.4 or lines[\"count\"] >= 6\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626155d-67a6-44c7-adce-a2b75b354020",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        \n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.image_list = self.load_image_list(path)\n",
    "    \n",
    "    \n",
    "    def load_image_list(self, path, is_training=True):\n",
    "        image_list = []\n",
    "        \n",
    "        # train, validation 폴더의 경우 Broken, Normal폴더로 나뉘어져 있음.\n",
    "        if is_training:            \n",
    "            for foldername in os.listdir(path):  # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test\n",
    "                folder = os.path.join(path, foldername)\n",
    "                #if (os.listdir(folder)[0] == 'Broken') and (os.listdir(folder)[1] == 'Normal'):   # os.listdir(folder) = ['Broken', 'Normal']\n",
    "                if foldername == 'Broken' or foldername == 'Normal':\n",
    "                    folder_br = os.path.join(path, foldername)   # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test \\\\ Broken\n",
    "                    folder_nor = os.path.join(path, foldername)  # # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test \\\\ Normal\n",
    "\n",
    "                    # Broken 이미지\n",
    "                    for filename in os.listdir(folder_br):\n",
    "                        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                            image_path_br = os.path.join(folder_br, filename)\n",
    "                            image_list.append((image_path_br, filename))  # 레이블 폴더명으로 추가\n",
    "\n",
    "                    # Normal 이미지\n",
    "                    for filename in os.listdir(folder_nor):\n",
    "                        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                            image_path_nor = os.path.join(folder_nor, filename)\n",
    "                            image_list.append((image_path_nor, filename))  # 레이블 폴더명으로 추가\n",
    "                            \n",
    "                # test폴더의 경우 Broken, Normal 폴더가 없고 두 개의 이미지가 혼합되어있음.        \n",
    "                else:\n",
    "                    for filename in os.listdir(folder):\n",
    "                        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                            image_path_test = os.path.join(folder, filename)\n",
    "                            image_list.append(image_path_test)\n",
    "        return image_list\n",
    "\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    \n",
    "    def getitem(self, index):\n",
    "        if self.is_training:\n",
    "            image_path, label = self.image_list[index]\n",
    "            image = Image.open(image_path) # .convert(\"L\")  # 흑백 이미지로 변환\n",
    "            \n",
    "            #lines = self.detect_lines(image)\n",
    "            # 선 굵기와 개수를 기반으로 오류 여부 판단\n",
    "            #is_error = lines[\"thickness\"] >= 0.4 or lines[\"count\"] >= 6\n",
    "\n",
    "            return image, label, is_error\n",
    "        \n",
    "        else:\n",
    "            image_path = self.image_list[index]\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            #lines = self.detect_lines(image)\n",
    "            # 선 굵기와 개수를 기반으로 오류 여부 판단\n",
    "            #is_error = lines[\"thickness\"] >= 0.4 or lines[\"count\"] >= 6\n",
    "\n",
    "            return image, is_error\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65831bc-80ba-4b32-808b-2ad68ec5584a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        \n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.image_list = self.load_image_list(path)\n",
    "    \n",
    "    \n",
    "    def load_image_list(self, path, is_training=True):\n",
    "        image_list = []\n",
    "        \n",
    "        # train, validation 폴더의 경우 Broken, Normal폴더로 나뉘어져 있음.\n",
    "        if is_training:            \n",
    "            for foldername in os.listdir(path):  # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test\n",
    "\n",
    "                if (os.listdir(folder)[0] == 'Broken') and (os.listdir(folder)[1] == 'Normal'):   # os.listdir(folder) = ['Broken', 'Normal']\n",
    "                    folder_br = os.path.join(folder, foldername)   # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test \\\\ Broken\n",
    "                    folder_nor = os.path.join(folder, foldername)  # # C:\\\\Users\\\\JungHyeona\\\\Documents\\\\Project\\\\AI_deeplearning\\\\image\\\\split\\\\  train or val or test \\\\ Normal\n",
    "\n",
    "                    # Broken 이미지\n",
    "                    for filename in os.listdir(folder_br):\n",
    "                        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                            image_path_br = os.path.join(folder_br, filename)\n",
    "                            image_list.append((image_path_br, filename))  # 레이블 폴더명으로 추가\n",
    "\n",
    "                    # Normal 이미지\n",
    "                    for filename in os.listdir(folder_nor):\n",
    "                        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                            image_path_nor = os.path.join(folder_nor, filename)\n",
    "                            image_list.append((image_path_nor, filename))  # 레이블 폴더명으로 추가\n",
    "                            \n",
    "                # test폴더의 경우 Broken, Normal 폴더가 없고 두 개의 이미지가 혼합되어있음.        \n",
    "                else:\n",
    "                    for filename in os.listdir(folder):\n",
    "                        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                            image_path_test = os.path.join(folder, filename)\n",
    "                            image_list.append(image_path_test)\n",
    "        return image_list\n",
    "\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    \n",
    "    def getitem(self, index):\n",
    "        if self.is_training:\n",
    "            image_path, label = self.image_list[index]\n",
    "            image = Image.open(image_path) # .convert(\"L\")  # 흑백 이미지로 변환\n",
    "            \n",
    "            #lines = self.detect_lines(image)\n",
    "            # 선 굵기와 개수를 기반으로 오류 여부 판단\n",
    "            #is_error = lines[\"thickness\"] >= 0.4 or lines[\"count\"] >= 6\n",
    "\n",
    "            return image, label, is_error\n",
    "        \n",
    "        else:\n",
    "            image_path = self.image_list[index]\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            #lines = self.detect_lines(image)\n",
    "            # 선 굵기와 개수를 기반으로 오류 여부 판단\n",
    "            #is_error = lines[\"thickness\"] >= 0.4 or lines[\"count\"] >= 6\n",
    "\n",
    "            return image, is_error\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b85d7-a175-4d7f-9f1c-1f0501023bc9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "    def load_image_list(self):\n",
    "        image_list = []\n",
    "        \n",
    "        folder_br = os.path.join(self.path, 'Broken')  # 에러 이미지 경로\n",
    "        folder_nor = os.path.join(self.path, 'Normal')  # 정상 이미지 경로\n",
    "        \n",
    "        for filename in os.listdir(folder_br):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path_br = os.path.join(folder_br, filename)\n",
    "                img_path_nor = os.path.join(folder_nor, filename)\n",
    "                \n",
    "                if os.path.isfile(img_path_nor):\n",
    "                    image_list.append((img_path_br, img_path_nor))\n",
    "        return image_list\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_list[index]\n",
    "        label = self.label_list[index]\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f21f8-fc64-4272-8919-7cdffd6d89d4",
   "metadata": {},
   "source": [
    "## 이미지 평균 및 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a27c696-89b6-40b1-a907-06ec86efbd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76a09710-376f-41ae-acf1-d1e8e929dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\train\\Broken\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\train\\Normal\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21736\\2502459435.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Dataset[T_co]'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'ConcatDataset[T_co]'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainset = BDataset(path + \"\\\\train\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47228912-9602-43bb-ba2b-810b9824e2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BDataset object at 0x000002D3BD423B50>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4df20f89-f9d7-4a22-8192-90934b57cbfd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = BDataset(path + \"\\\\train\", transform)\n",
    "val_set = BDataset(path + \"\\\\val\", transform)\n",
    "test_set = BDataset(path + \"\\\\test\", transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ed157-84a4-429b-841f-11a263f60138",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 결과 -> 해당 결과의 경우 train, val, test별로의 평균값이 아닌 파일을 나누기 전 Normal, Broken을 가져왔을 때 돌려본 결과.\n",
    "\n",
    "### normal : 1000개\n",
    "shape: (1000, 3, 808, 1182)<br>\n",
    "min: (0.0, 0.05882353, 0.019607844)<br>\n",
    "max: (0.92156863, 0.92156863, 0.92941177)<br>\n",
    "mean: (0.11181334, 0.111890435, 0.1135668)<br>\n",
    "std: (0.026530448, 0.02637402, 0.02658573)\n",
    "\n",
    "### broken\n",
    "shape: (523, 3, 808, 1182)<br>\n",
    "min: (0.0, 0.05882353, 0.019607844)<br>\n",
    "max: (0.92156863, 0.92156863, 0.92941177)<br>\n",
    "mean: (0.11188801, 0.111966185, 0.11256382)<br>\n",
    "std: (0.03245135, 0.032322615, 0.03192493)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f170c1-39a3-4685-92b0-8b9c0af2cc95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 이미지의 RGB 채널별 통계량 확인 함수\n",
    "def print_stats(dataset):\n",
    "    imgs = np.array([img.numpy() for img, _ in dataset])\n",
    "    print(f'shape: {imgs.shape}')\n",
    "    \n",
    "    min_r = np.min(imgs, axis=(2, 3))[:, 0].min()\n",
    "    min_g = np.min(imgs, axis=(2, 3))[:, 1].min()\n",
    "    min_b = np.min(imgs, axis=(2, 3))[:, 2].min()\n",
    "\n",
    "    max_r = np.max(imgs, axis=(2, 3))[:, 0].max()\n",
    "    max_g = np.max(imgs, axis=(2, 3))[:, 1].max()\n",
    "    max_b = np.max(imgs, axis=(2, 3))[:, 2].max()\n",
    "\n",
    "    mean_r = np.mean(imgs, axis=(2, 3))[:, 0].mean()\n",
    "    mean_g = np.mean(imgs, axis=(2, 3))[:, 1].mean()\n",
    "    mean_b = np.mean(imgs, axis=(2, 3))[:, 2].mean()\n",
    "\n",
    "    std_r = np.std(imgs, axis=(2, 3))[:, 0].std()\n",
    "    std_g = np.std(imgs, axis=(2, 3))[:, 1].std()\n",
    "    std_b = np.std(imgs, axis=(2, 3))[:, 2].std()\n",
    "    \n",
    "    print(f'min: {min_r, min_g, min_b}')\n",
    "    print(f'max: {max_r, max_g, max_b}')\n",
    "    print(f'mean: {mean_r, mean_g, mean_b}')\n",
    "    print(f'std: {std_r, std_g, std_b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11415f-8d79-4eec-8069-3c3ccd9e6f11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_stats(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0c5df-769e-4581-8e0a-78a0ec38a175",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae3295-c81d-4f4f-b743-62cd913d2777",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "transform = transform = transforms.Compose([\n",
    "                transforms.Resize((512, 512)),\n",
    "                transforms.RandomHorizontalFlip(),   # 좌우반전\n",
    "                # transforms.RandomResizedCrop((60, 60)),   # (w, h). 이미지에서 잘라낼 크기 설정하면, 크기만큼 랜덤으로 잘린다.\n",
    "                # transforms.RandomErasing(),      # 이미지에서 랜덤하게 박스 모양으로 지운다. PIL image에 바로 적용 불가 -> tensor 필요\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea55ce31-ee48-4b6e-8ac2-28ef34ddc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, path):\n",
    "        #self.path = path\n",
    "        normalize = transforms.Normalize((0.111850675, 0.11192831, 0.11306531), (0.029490899, 0.0293483175, 0.029255329999999996))\n",
    "        \n",
    "        transform_train = transforms.Compose([\n",
    "                        transforms.Resize((512, 512)),\n",
    "                        #transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor(),\n",
    "                        normalize\n",
    "                        ])\n",
    "        transform_test = transforms.Compose([\n",
    "                        transforms.Resize((512, 512)),\n",
    "                        transforms.ToTensor(),\n",
    "                        normalize\n",
    "                        ])\n",
    "        \n",
    "        trainset = BDataset(path + \"\\\\train\", transform_train)\n",
    "        valset = BDataset(path + \"\\\\val\", transform_train)\n",
    "        testset = BDataset(path + \"\\\\test\", transform_test)\n",
    "        \n",
    "        train_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(valset, batch_size=64, shuffle=True, num_workers=4)\n",
    "        test_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "    def getloader(self):\n",
    "        return self.train_loader, self.val_loader#, self.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26a8f537-a107-480d-979e-bf97e89d6b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\train\\Broken\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\train\\Normal\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\val\\Broken\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\val\\Normal\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\train\\Broken\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\train\\Normal\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\val\\Broken\n",
      "C:\\Users\\JungHyeona\\Documents\\Project\\AI_deeplearning\\image\\split\\val\\Normal\n"
     ]
    }
   ],
   "source": [
    "train_loader = Dataloader(path)\n",
    "val_loader = Dataloader(path)\n",
    "#test_loader = Dataloader(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d575e3-134d-4e75-9d76-456e5d3084b2",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "577d1aa4-c2a4-4063-b706-f8209c9a7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # (512, 512, 3) -> (32, 32, 32), (16, 16, 32)\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  #cnn layer\n",
    "            nn.BatchNorm2d(64),    #batch layer\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  #cnn layer\n",
    "            nn.BatchNorm2d(64),    #batch layer\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  #cnn layer\n",
    "            nn.BatchNorm2d(64),    #batch layer\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),    #pooling layer\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  #cnn layer\n",
    "            nn.BatchNorm2d(64),    #batch layer\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  #cnn layer\n",
    "            nn.BatchNorm2d(64),    #batch layer\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  #cnn layer\n",
    "            nn.BatchNorm2d(64),    #batch layer\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),    #pooling layer\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  #cnn layer\n",
    "            nn.BatchNorm2d(128),    #batch layer\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*4*128, 18),\n",
    "            nn.Linear(18, 2)  # 수정 필요한 부분: 출력 뉴런 수\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "637aa674-6f3c-4f82-86bc-845c6251318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): Flatten(start_dim=1, end_dim=-1)\n",
       "    (17): Linear(in_features=2048, out_features=18, bias=True)\n",
       "    (18): Linear(in_features=18, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "# GPU 사용 가능 여부에 따라 디바이스 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e8e2283-f736-46f4-b211-6e542287caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0002\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fe44ac8-77d1-419d-993d-85ace2d17d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dataloader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21736\\1621957361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Dataloader' object is not iterable"
     ]
    }
   ],
   "source": [
    "for X, Y in train_loader:\n",
    "    print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b95a7ac-26e1-4edc-99be-9b3e6705a049",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dataloader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21736\\509307796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mavg_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m# image is already size of (28x28), no reshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# label is not one-hot encoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Dataloader' object is not iterable"
     ]
    }
   ],
   "source": [
    "#total_batch = len(train_loader)\n",
    "#print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "for epoch in range(10):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in train_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = loss_func(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a47c26-8566-41e1-9e37-f1551d5be1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89c2af-c3a0-45e6-a109-9fbdc1536296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "val_accuracy = evaluate(model, val_loader, device)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a8d80-7340-41d6-9989-ce8c1faecfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model, path+'B_cnn.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
